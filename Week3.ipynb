{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3oamfL0SQYH",
        "outputId": "6ac73358-d8ae-4e7d-a27c-8df62a4e9fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WiDS-2023'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 49 (delta 16), reused 38 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (49/49), 15.11 MiB | 34.38 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Dhvanil-CSE/WiDS-2023.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/WiDS-2023/Week3/Week_3.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQPD20HISmV5",
        "outputId": "a214394c-8845-4262-9837-3577181cf7fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WiDS-2023/Week3/Week_3.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/WiDS-2023/Week3/Week_3.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIt1ab-EV3ZN",
        "outputId": "cac3f954-4f1a-40c4-b86c-340977c73c38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"nbformat\": 4,\n",
            "  \"nbformat_minor\": 0,\n",
            "  \"metadata\": {\n",
            "    \"colab\": {\n",
            "      \"provenance\": []\n",
            "    },\n",
            "    \"kernelspec\": {\n",
            "      \"name\": \"python3\",\n",
            "      \"display_name\": \"Python 3\"\n",
            "    },\n",
            "    \"language_info\": {\n",
            "      \"name\": \"python\"\n",
            "    }\n",
            "  },\n",
            "  \"cells\": [\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"#MNIST\\n\",\n",
            "        \"Our objective is to build a neural network for the classification of the MNIST dataset. This neural network will comprise two layers, each with 10 nodes, and an input layer with 784 nodes corresponding to the image pixels. The specific structure of the neural network is outlined below, where $X$ represents the input, $A^{[0]}$ denotes the first layer, $Z^{[1]}$ signifies the unactivated layer 1, $A^{[1]}$ stands for the activated layer 1, and so forth. The weights and biases are represented by $W$ and $b$ respectively:\\n\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"4lFWhSEEwc9F\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"<div align=\\\"center\\\">\\n\",\n",
            "        \"\\n\",\n",
            "        \"$A^{[0]}=X$\\n\",\n",
            "        \"\\n\",\n",
            "        \"$Z^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$\\n\",\n",
            "        \"\\n\",\n",
            "        \"$A^{[1]}=\\\\text{ReLU}(Z^{[1]})$\\n\",\n",
            "        \"\\n\",\n",
            "        \"$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\\n\",\n",
            "        \"\\n\",\n",
            "        \"$A^{[2]}=\\\\text{softmax}(Z^{[2]})$\\n\",\n",
            "        \"</div>\\n\",\n",
            "        \"\\n\",\n",
            "        \"\\n\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"dDanK4nEwfhh\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"You have the flexibility to create any function within or outside the class, allowing you to modify parameters as needed\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"YzBJgODl4aDp\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"#importing libraries\\n\",\n",
            "        \"import pandas as pd\\n\",\n",
            "        \"import numpy as np\\n\",\n",
            "        \"from keras.datasets import mnist\\n\",\n",
            "        \"import matplotlib.pyplot as plt\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"8A6ScQ-8lzWy\"\n",
            "      },\n",
            "      \"execution_count\": null,\n",
            "      \"outputs\": []\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"### Required functions\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"TGVN81yBnufX\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"execution_count\": null,\n",
            "      \"metadata\": {\n",
            "        \"id\": \"N4A3X8zjh5My\"\n",
            "      },\n",
            "      \"outputs\": [],\n",
            "      \"source\": [\n",
            "        \"# activation and loss functions\\n\",\n",
            "        \"def ReLU():\\n\",\n",
            "        \"    pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"def derivative_ReLU():\\n\",\n",
            "        \"    pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"def softmax():\\n\",\n",
            "        \"    pass\\n\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"#complete the class of neural network\\n\",\n",
            "        \"\\n\",\n",
            "        \"class NN:\\n\",\n",
            "        \"  def __init__(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def forward_propagation(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def one_hot(self): #return a 0 vector with 1 only in the position corresponding to the value in test target\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def backward_propagation(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def update_params(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def get_predictions(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def get_accuracy(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def gradient_descent(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def make_predictions(self):\\n\",\n",
            "        \"      pass\\n\",\n",
            "        \"\\n\",\n",
            "        \"  def show_prediction(self): #show the prediction and actual output for an image in mnist dataset\\n\",\n",
            "        \"      pass\\n\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"Vqdn0Wv0mFNE\"\n",
            "      },\n",
            "      \"execution_count\": null,\n",
            "      \"outputs\": []\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"## main\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"FsgNaz6qmoLI\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"iIbC5z1Lmlcr\"\n",
            "      },\n",
            "      \"execution_count\": null,\n",
            "      \"outputs\": []\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"###preprocessing the data\\n\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"ymme4NNNmws9\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"# all values of pixels should be in range[0,1]\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"B8YjLpUwm678\"\n",
            "      },\n",
            "      \"execution_count\": null,\n",
            "      \"outputs\": []\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"###Model Training\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"B5dqfE25m7ZD\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"#training model using gradient descent\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"G05ggxM1m_n0\"\n",
            "      },\n",
            "      \"execution_count\": null,\n",
            "      \"outputs\": []\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"### Viewing Results\\n\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"sa-CT3UnnAsr\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"#viewing prediction for 10 random images in dataset\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"WV9UEIHbnJKd\"\n",
            "      },\n",
            "      \"execution_count\": null,\n",
            "      \"outputs\": []\n",
            "    }\n",
            "  ]\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"#MNIST\\n\",\n",
        "        \"Our objective is to build a neural network for the classification of the MNIST dataset. This neural network will comprise two layers, each with 10 nodes, and an input layer with 784 nodes corresponding to the image pixels. The specific structure of the neural network is outlined below, where $X$ represents the input, $A^{[0]}$ denotes the first layer, $Z^{[1]}$ signifies the unactivated layer 1, $A^{[1]}$ stands for the activated layer 1, and so forth. The weights and biases are represented by $W$ and $b$ respectively:\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"4lFWhSEEwc9F\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"<div align=\\\"center\\\">\\n\",\n",
        "        \"\\n\",\n",
        "        \"$A^{[0]}=X$\\n\",\n",
        "        \"\\n\",\n",
        "        \"$Z^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$\\n\",\n",
        "        \"\\n\",\n",
        "        \"$A^{[1]}=\\\\text{ReLU}(Z^{[1]})$\\n\",\n",
        "        \"\\n\",\n",
        "        \"$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\\n\",\n",
        "        \"\\n\",\n",
        "        \"$A^{[2]}=\\\\text{softmax}(Z^{[2]})$\\n\",\n",
        "        \"</div>\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"dDanK4nEwfhh\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"You have the flexibility to create any function within or outside the class, allowing you to modify parameters as needed\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"YzBJgODl4aDp\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"#importing libraries\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"from keras.datasets import mnist\\n\",\n",
        "        \"import matplotlib.pyplot as plt\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"8A6ScQ-8lzWy\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"### Required functions\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"TGVN81yBnufX\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"N4A3X8zjh5My\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# activation and loss functions\\n\",\n",
        "        \"def ReLU():\\n\",\n",
        "        \"    return np.maximum(0,x)\\n\",\n",
        "        \"\\n\",\n",
        "        \"def derivative_ReLU():\\n\",\n",
        "        \"    return np.where(x>0 , 1, 0)\\n\",\n",
        "        \"\\n\",\n",
        "        \"def softmax():\\n\",\n",
        "        \"expx = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return expx / np.sum(expx, axis=-1, keepdims=True)\\n\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"#complete the class of neural network\\n\",\n",
        "        \"\\n\",\n",
        "        \"class NN:\\n\",\n",
        "        \"  def __init__(self):\\n\",\n",
        "        \"      self.w1 = np.random.randn(784, 10)\n",
        "      self.b1 = np.zeros((1, 10))\n",
        "      self.w2 = np.random.randn(10, 10)\n",
        "      self.b2 = np.zeros((1, 10))\n",
        "      self.w3 = np.random.randn(10, 10)\n",
        "      self.b3 = np.zeros((1, 10))\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def forward_propagation(self):\\n\",\n",
        "        \"      self.A0 = X\n",
        "      self.Z1 = np.dot(self.A0, self.w1) + self.b1\n",
        "      self.A1 = ReLU(self.Z1)\n",
        "      self.Z2 = np.dot(self.A1, self.w2) + self.b2\n",
        "      self.A2 = ReLU(self.Z2)\n",
        "      self.Z3 = np.dot(self.A2, self.w3) + self.b3\n",
        "      self.A3 = softmax(self.Z3)\n",
        "      return self.A3\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def one_hot(self): #return a 0 vector with 1 only in the position corresponding to the value in test target\\n\",\n",
        "        \"      one_hot_labels = np.zeros((len(label), 10))\n",
        "    for i, label in enumerate(label):\n",
        "      one_hot_labels[i, label] = 1\n",
        "    return one_hot_labels\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def backward_propagation(self):\\n\",\n",
        "        \"     loss = -np.sum(y * np.log(self.A3 + 1e-15)) / X.shape[0]\n",
        "        self.dZ3 = self.A3 - y\n",
        "        self.dW3 = np.dot(self.A2.T, self.dZ3)\n",
        "        self.db3 = np.sum(self.dZ3, axis=0, keepdims=True)\n",
        "        self.dZ2 = np.dot(self.dZ3, self.w3.T) * derivative_ReLU(self.Z2)\n",
        "        self.dW2 = np.dot(self.A1.T, self.dZ2)\n",
        "        self.db2 = np.sum(self.dZ2, axis=0, keepdims=True)\n",
        "        self.dZ1 = np.dot(self.dZ2, self.w2.T) * derivative_ReLU(self.Z1)\n",
        "        self.dW1 = np.dot(X.T, self.dZ1)\n",
        "        self.db1 = np.sum(self.dZ1, axis=0, keepdims=True)\n",
        "        return loss\n",
        "\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def update_params(self):\\n\",\n",
        "        \"      self.w3 -= 0.0001 * self.dW3\n",
        "        self.b3 -= 0.0001 * self.db3\n",
        "        self.w2 -= 0.0001 * self.dW2\n",
        "        self.b2 -= 0.0001 * self.db2\n",
        "        self.w1 -= 0.0001 * self.dW1\n",
        "        self.b1 -= 0.0001 * self.db1\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def get_predictions(self):\\n\",\n",
        "        \"      return np.argmax(self.forward_propagation(X), axis=1)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def get_accuracy(self):\\n\",\n",
        "        \"      accuracy = np.mean(self.get_predictions(X) == np.argmax(y, axis=1))\n",
        "      return accuracys\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def gradient_descent(self):\\n\",\n",
        "        \"      for epoch in range(epochs):\n",
        "            self.forward_propagation(X_train)\n",
        "            loss = self.backward_propagation(X_train, y_train)\n",
        "            self.update_params()\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def make_predictions(self):\\n\",\n",
        "        \"      return self.get_predictions(X)\\n\",\n",
        "        \"\\n\",\n",
        "        \"  def show_prediction(self): #show the prediction and actual output for an image in mnist dataset\\n\",\n",
        "        \"      sample = np.random.choice(X.shape[0], num_samples, replace=False)\n",
        "        for index in sample:\n",
        "            sample_image = X[index].reshape(28, 28)\n",
        "            actual_label = y[index]\n",
        "            prediction = self.get_predictions(X[index].reshape(1, -1))[0]\n",
        "            plt.imshow(sample_image, cmap='Greens')\n",
        "            plt.title(f\"Actual: {actual_label}, Predicted: {prediction}\")\n",
        "            plt.show()\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Vqdn0Wv0mFNE\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"## main\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"FsgNaz6qmoLI\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"iIbC5z1Lmlcr\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"###preprocessing the data\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ymme4NNNmws9\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"# all values of pixels should be in range[0,1]\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"B8YjLpUwm678\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"###Model Training\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"B5dqfE25m7ZD\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"#training model using gradient descent\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"G05ggxM1m_n0\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"source\": [\n",
        "        \"### Viewing Results\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"sa-CT3UnnAsr\"\n",
        "      }\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"#viewing prediction for 10 random images in dataset\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"WV9UEIHbnJKd\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "pjsk92PaWBLC",
        "outputId": "627a1db0-29dd-4ef0-db3a-25b2d03e9d67"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 98) (<ipython-input-4-c98f38cb3077>, line 98)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-c98f38cb3077>\"\u001b[0;36m, line \u001b[0;32m98\u001b[0m\n\u001b[0;31m    \"expx = np.exp(x - np.max(x, axis=-1, keepdims=True))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 98)\n"
          ]
        }
      ]
    }
  ]
}